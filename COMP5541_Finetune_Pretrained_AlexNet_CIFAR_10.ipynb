{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yjwu17/Course/blob/main/COMP5541_Finetune_Pretrained_AlexNet_CIFAR_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tuning Pretrained AlexNet in PyTorch\n",
        "\n",
        "AlexNet is a deep convolutional neural network, which was initially developed by Alex Krizhevsky and his colleagues back in 2012. It was designed to classify images for the ImageNet LSVRC-2010 competition where it achieved state of the art results. You can read in detail about the model in the original research paper.\n",
        "\n",
        "We want to **fine-tune a AlexNet model based on the AlexNet model pre-trained on imagenet**. ImageNet is an image database organized according to the WordNet hierarchy (currently only the nouns), in which each node of the hierarchy is depicted by hundreds and thousands of images.\n",
        "\n",
        "Let's start by loading and then pre-processing the data. For our purposes, we will be using the CIFAR10 dataset. The dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
        "\n",
        "![CIFAR10](https://drive.google.com/uc?export=view&id=13c1WiUPbOP_RbYcABeAJzBCBC0pifrnZ)"
      ],
      "metadata": {
        "id": "ob40bHNL8IML"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Libraries\n",
        "\n",
        "The Notebook knows to use a GPU to train the model if it's available."
      ],
      "metadata": {
        "id": "VGo_qfSb8i46"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_2OoM5JQVmT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from datetime import datetime\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the CIFAR10 Dataset\n",
        "\n",
        "Using torchvision (a helper library for computer vision tasks), we will load our dataset. This method has some helper functions that makes pre-processing pretty easy and straight-forward. Let's define the functions get_train_valid_loader and get_test_loader, and then call them to load in and process our CIFAR-10 data:"
      ],
      "metadata": {
        "id": "Twnee3ln8lIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_train_valid_loader(\n",
        "    data_dir, batch_size, augment, random_seed, valid_size=0.1, shuffle=True\n",
        "):\n",
        "    normalize = transforms.Normalize(\n",
        "        mean=[0.4914, 0.4822, 0.4465],\n",
        "        std=[0.2023, 0.1994, 0.2010],\n",
        "    )\n",
        "\n",
        "    # define transforms\n",
        "    transform = transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize((227, 227)),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # load the dataset\n",
        "    train_dataset = datasets.CIFAR10(\n",
        "        root=data_dir,\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transform,\n",
        "    )\n",
        "\n",
        "    valid_dataset = datasets.CIFAR10(\n",
        "        root=data_dir,\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transform,\n",
        "    )\n",
        "\n",
        "    num_train = len(train_dataset)\n",
        "    indices = list(range(num_train))\n",
        "    split = int(np.floor(valid_size * num_train))\n",
        "\n",
        "    if shuffle:\n",
        "        np.random.seed(random_seed)\n",
        "        np.random.shuffle(indices)\n",
        "\n",
        "    train_idx, valid_idx = indices[split:], indices[:split]\n",
        "    train_sampler = SubsetRandomSampler(train_idx)\n",
        "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset, batch_size=batch_size, sampler=train_sampler\n",
        "    )\n",
        "\n",
        "    valid_loader = torch.utils.data.DataLoader(\n",
        "        valid_dataset, batch_size=batch_size, sampler=valid_sampler\n",
        "    )\n",
        "\n",
        "    return (train_loader, valid_loader)\n",
        "\n",
        "\n",
        "def get_test_loader(data_dir, batch_size, shuffle=True):\n",
        "    normalize = transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225],\n",
        "    )\n",
        "\n",
        "    # define transform\n",
        "    transform = transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize((227, 227)),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    dataset = datasets.CIFAR10(\n",
        "        root=data_dir,\n",
        "        train=False,\n",
        "        download=True,\n",
        "        transform=transform,\n",
        "    )\n",
        "\n",
        "    data_loader = torch.utils.data.DataLoader(\n",
        "        dataset, batch_size=batch_size, shuffle=shuffle\n",
        "    )\n",
        "\n",
        "    return data_loader\n",
        "\n",
        "\n",
        "# CIFAR10 dataset\n",
        "train_loader, valid_loader = get_train_valid_loader(\n",
        "    data_dir=\"./data\", batch_size=64, augment=False, random_seed=1\n",
        ")\n",
        "\n",
        "test_loader = get_test_loader(data_dir=\"./data\", batch_size=64)"
      ],
      "metadata": {
        "id": "muLZxw7_TG5O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cb7257c-f406-4870-b3aa-1899535bb55f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:04<00:00, 35551477.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building AlexNet\n",
        "\n",
        "- The first step to defining any neural network (whether a CNN or not) in PyTorch is to define a class that inherits `nn.Module` as it contains many of the methods that we will need to utilize\n",
        "- There are two main steps after that. First is initializing the layers that we are going to use in our CNN inside `__init__`, and the other is to define the sequence in which those layers will process the image. This is defined inside the forward function\n",
        "- For the architecture itself, we first define the convolutional layers using the `nn.Conv2D` function with the appropriate kernel size and the input/output channels. We also apply max pooling using `nn.MaxPool2D` function. The nice thing about PyTorch is that we can combine the convolutional layer, activation function, and max pooling into one single layer (they will be separately applied, but it helps with organization) using the `nn.Sequential` function\n",
        "- Then we define the fully connected layers using linear (`nn.Linear`) and dropout (`nn.Dropout`) along with ReLu activation function (`nn.ReLU`) and combining these with the nn.Sequential function\n",
        "- Finally, our last layer outputs 10 neurons which are our final predictions for the 10 classes of objects\n"
      ],
      "metadata": {
        "id": "urw6pzcZT6Xi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num_classes = 1000, dropout = 0.5):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=dropout),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=dropout),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "K5hfwshJR9fz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting Hyperparameters\n",
        "\n",
        "Before training, we need to set some hyperparameters, such as the loss function and the optimizer to be used along with batch size, learning rate, and number of epochs."
      ],
      "metadata": {
        "id": "fLywGzaK-49r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# +++++++++++++++++++++++++++++++++++++\n",
        "imagenet_num_classes = 1000\n",
        "cifar_num_classes = 10\n",
        "# +++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "num_epochs = 20\n",
        "batch_size = 64\n",
        "learning_rate = 0.005\n",
        "\n",
        "model = AlexNet(imagenet_num_classes).to(device)\n",
        "\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.005, momentum = 0.9)"
      ],
      "metadata": {
        "id": "VlgLxD1BSFoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Pretrained Weights on ImageNet\n",
        "\n",
        "The pre-trained model expects input images normalized in the same way, i.e. mini-batches of 3-channel RGB images of shape `(3 x H x W)`, where `H` and `W` are expected to be at least 224. The images have to be loaded in to a range of `[0, 1]` and then normalized using mean = `[0.485, 0.456, 0.406]` and std = `[0.229, 0.224, 0.225]`."
      ],
      "metadata": {
        "id": "_cLopkvOOBIg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://download.pytorch.org/models/alexnet-owt-7be5be79.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_0VEOSLV20_",
        "outputId": "6423895a-5ebd-488d-f183-22f8437c874b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-07 01:05:42--  https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\n",
            "Resolving download.pytorch.org (download.pytorch.org)... 13.249.85.22, 13.249.85.10, 13.249.85.72, ...\n",
            "Connecting to download.pytorch.org (download.pytorch.org)|13.249.85.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 244408911 (233M) [application/x-www-form-urlencoded]\n",
            "Saving to: ‘alexnet-owt-7be5be79.pth.2’\n",
            "\n",
            "alexnet-owt-7be5be7 100%[===================>] 233.09M  31.4MB/s    in 6.8s    \n",
            "\n",
            "2023-06-07 01:05:49 (34.4 MB/s) - ‘alexnet-owt-7be5be79.pth.2’ saved [244408911/244408911]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "state_dict = torch.load(\"/content/alexnet-owt-7be5be79.pth\")\n",
        "model.load_state_dict(state_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iSJAfBhOmq8",
        "outputId": "f9af8e87-c81c-48db-ac14-ebdab9cedf06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The Pretrained AlexNet Architecture on ImageNet\n",
        "\n",
        "The default output of the pretrained AlexNet on ImageNet is 1000 classes, we have to adjust the network structure to fit this."
      ],
      "metadata": {
        "id": "9LOrsF19Z1CL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# before modify\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sm04UmSDW4OI",
        "outputId": "b0580781-12cb-4c0b-adae-ba217bdac13c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We can choose to replace all layers in the classifier, or just replace the last layer.\n",
        "modify_whole_classifier = False\n",
        "\n",
        "if modify_whole_classifier:\n",
        "    model.classifier = nn.Sequential()\n",
        "    model.classifier.add_module(\"0\", nn.Dropout(p=0.5))\n",
        "    model.classifier.add_module(\"1\", nn.Linear(256 * 6 * 6, 4096))\n",
        "    model.classifier.add_module(\"2\", nn.ReLU(inplace=True))\n",
        "    model.classifier.add_module(\"3\", nn.Dropout(p=0.5))\n",
        "    model.classifier.add_module(\"4\", nn.Linear(4096, 4096))\n",
        "    model.classifier.add_module(\"5\", nn.ReLU(inplace=True))\n",
        "    model.classifier.add_module(\"6\", nn.Linear(4096, cifar_num_classes))\n",
        "    model.to(device)\n",
        "else:\n",
        "    model.classifier[6] = nn.Linear(4096, cifar_num_classes)\n",
        "    model.to(device)"
      ],
      "metadata": {
        "id": "vnTdjLajWkmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# after modify\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aVlg6F_YxNl",
        "outputId": "951679e6-e3ba-495b-d6e5-598759c7a818"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training\n",
        "\n",
        "We are ready to train our model at this point:"
      ],
      "metadata": {
        "id": "1IcOPh6vMODr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_step = len(train_loader)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # Move tensors to the configured device\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print ('{} - Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                   .format(str(datetime.now()), epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
        "\n",
        "    # Validation\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in valid_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            del images, labels, outputs\n",
        "\n",
        "        print('Accuracy of the network on the {} validation images: {} %'.format(5000, 100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NAGdpAolF3C",
        "outputId": "63ebeecf-b5cc-4d7b-897b-6a23a2c9fde9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20], Step [704/704], Loss: 0.8373\n",
            "Accuracy of the network on the 5000 validation images: 80.28 %\n",
            "Epoch [2/20], Step [704/704], Loss: 0.7658\n",
            "Accuracy of the network on the 5000 validation images: 83.44 %\n",
            "Epoch [3/20], Step [704/704], Loss: 0.0689\n",
            "Accuracy of the network on the 5000 validation images: 84.78 %\n",
            "Epoch [4/20], Step [704/704], Loss: 0.3098\n",
            "Accuracy of the network on the 5000 validation images: 83.78 %\n",
            "Epoch [5/20], Step [704/704], Loss: 0.2478\n",
            "Accuracy of the network on the 5000 validation images: 84.08 %\n",
            "Epoch [6/20], Step [704/704], Loss: 0.0839\n",
            "Accuracy of the network on the 5000 validation images: 81.9 %\n",
            "Epoch [7/20], Step [704/704], Loss: 0.1804\n",
            "Accuracy of the network on the 5000 validation images: 82.72 %\n",
            "Epoch [8/20], Step [704/704], Loss: 0.5683\n",
            "Accuracy of the network on the 5000 validation images: 82.76 %\n",
            "Epoch [9/20], Step [704/704], Loss: 0.4275\n",
            "Accuracy of the network on the 5000 validation images: 80.3 %\n",
            "Epoch [10/20], Step [704/704], Loss: 0.1408\n",
            "Accuracy of the network on the 5000 validation images: 81.76 %\n",
            "Epoch [11/20], Step [704/704], Loss: 1.3011\n",
            "Accuracy of the network on the 5000 validation images: 80.94 %\n",
            "Epoch [12/20], Step [704/704], Loss: 0.3738\n",
            "Accuracy of the network on the 5000 validation images: 82.32 %\n",
            "Epoch [13/20], Step [704/704], Loss: 0.1614\n",
            "Accuracy of the network on the 5000 validation images: 82.08 %\n",
            "Epoch [14/20], Step [704/704], Loss: 0.1632\n",
            "Accuracy of the network on the 5000 validation images: 82.82 %\n",
            "Epoch [15/20], Step [704/704], Loss: 0.1962\n",
            "Accuracy of the network on the 5000 validation images: 82.3 %\n",
            "Epoch [16/20], Step [704/704], Loss: 0.3734\n",
            "Accuracy of the network on the 5000 validation images: 79.98 %\n",
            "Epoch [17/20], Step [704/704], Loss: 1.1105\n",
            "Accuracy of the network on the 5000 validation images: 81.18 %\n",
            "Epoch [18/20], Step [704/704], Loss: 0.5894\n",
            "Accuracy of the network on the 5000 validation images: 82.3 %\n",
            "Epoch [19/20], Step [704/704], Loss: 0.2684\n",
            "Accuracy of the network on the 5000 validation images: 82.3 %\n",
            "Epoch [20/20], Step [704/704], Loss: 0.1633\n",
            "Accuracy of the network on the 5000 validation images: 83.56 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test\n",
        "\n",
        "Now, we see how our model performs on unseen data:"
      ],
      "metadata": {
        "id": "gQZo6N-5NIy0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        del images, labels, outputs\n",
        "\n",
        "    print('Accuracy of the network on the {} test images: {} %'.format(10000, 100 * correct / total))"
      ],
      "metadata": {
        "id": "6u1CvrSQNJ7Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0519d14b-dc77-42ad-bbd8-b15e5daa7e7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 82.83 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resources\n",
        "\n",
        "- [Writing AlexNet from Scratch in PyTorch](https://blog.paperspace.com/alexnet-pytorch/#training)\n",
        "- [AlexNet | PyTorch](https://pytorch.org/hub/pytorch_vision_alexnet/)\n",
        "- [Classify CIFAR10 images using pretrained AlexNet with PyTorch](https://www.youtube.com/watch?v=BrwJp-JuIOw)\n"
      ],
      "metadata": {
        "id": "OWQ9Lrw1MbBt"
      }
    }
  ]
}